{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import openai\n",
    "import whisper\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import tiktoken\n",
    "\n",
    "import pickle\n",
    "\n",
    "from pytube import YouTube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = whisper.load_model('base')\n",
    "nltk.download('punkt')  # download the NLTK tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Video\n",
    "\n",
    "v_url_short = \"https://www.youtube.com/watch?v=DuaTGng9tRU\"\n",
    "v_url_long = \"https://www.youtube.com/watch?v=sY8aFSY2zv4\"\n",
    "youtube_video = YouTube(v_url) # Select YT video\n",
    "\n",
    "print(youtube_video.title)\n",
    "\n",
    "audio_stream_set = youtube_video.streams.filter(only_audio = True)\n",
    "audio_stream = audio_stream_set.first() # Select quality audio stream\n",
    "\n",
    "try:\n",
    "    audio_stream.download(filename = 'test_video.mp4') # Download video\n",
    "except Exception as e:\n",
    "    print(\"An error occured: e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transcribe and save text as csv divided by sentences\n",
    "\n",
    "path = 'test_video.mp4'\n",
    "t_model = whisper.transcribe(model= model, audio= 'test_video.mp4', fp16 = False) # Get transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and save as csv file\n",
    "transcript = t_model['text']\n",
    "\n",
    "# create a Pandas DataFrame with one row for each sentence\n",
    "trans_df = pd.DataFrame({'content': nltk.sent_tokenize(transcript)})\n",
    "\n",
    "# add a new column with the length of each sentence\n",
    "trans_df['title'] = youtube_video.title\n",
    "trans_df['token'] = trans_df['content'].apply(len)\n",
    "trans_df = trans_df.reset_index()\n",
    "trans_df = trans_df[['title', 'index', 'content', 'token']]\n",
    "\n",
    "# save the DataFrame to a CSV file\n",
    "trans_df.to_csv('video_text_long.csv', index=False)\n",
    "\n",
    "# print the DataFrame\n",
    "trans_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2789 rows in the data.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>heading</th>\n",
       "      <th>content</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jordan Peterson: Life, Death, Power, Fame, and...</td>\n",
       "      <td>0</td>\n",
       "      <td>battle not with monsters, lest ye become a mo...</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jordan Peterson: Life, Death, Power, Fame, and...</td>\n",
       "      <td>1</td>\n",
       "      <td>And if you gaze into the abyss, the abyss gaze...</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jordan Peterson: Life, Death, Power, Fame, and...</td>\n",
       "      <td>2</td>\n",
       "      <td>Right.</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jordan Peterson: Life, Death, Power, Fame, and...</td>\n",
       "      <td>3</td>\n",
       "      <td>But I would say, bring it on.</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jordan Peterson: Life, Death, Power, Fame, and...</td>\n",
       "      <td>4</td>\n",
       "      <td>If you gaze into the abyss long enough, you se...</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jordan Peterson: Life, Death, Power, Fame, and...</td>\n",
       "      <td>5</td>\n",
       "      <td>Are you sure about that?</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jordan Peterson: Life, Death, Power, Fame, and...</td>\n",
       "      <td>6</td>\n",
       "      <td>I'm betting my life on it.</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jordan Peterson: Life, Death, Power, Fame, and...</td>\n",
       "      <td>7</td>\n",
       "      <td>Following is a conversation with Jordan Peters...</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Jordan Peterson: Life, Death, Power, Fame, and...</td>\n",
       "      <td>8</td>\n",
       "      <td>This is the Lex Friedman podcast to support it.</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Jordan Peterson: Life, Death, Power, Fame, and...</td>\n",
       "      <td>9</td>\n",
       "      <td>Please check out our sponsors in the description.</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  heading  \\\n",
       "0  Jordan Peterson: Life, Death, Power, Fame, and...        0   \n",
       "1  Jordan Peterson: Life, Death, Power, Fame, and...        1   \n",
       "2  Jordan Peterson: Life, Death, Power, Fame, and...        2   \n",
       "3  Jordan Peterson: Life, Death, Power, Fame, and...        3   \n",
       "4  Jordan Peterson: Life, Death, Power, Fame, and...        4   \n",
       "5  Jordan Peterson: Life, Death, Power, Fame, and...        5   \n",
       "6  Jordan Peterson: Life, Death, Power, Fame, and...        6   \n",
       "7  Jordan Peterson: Life, Death, Power, Fame, and...        7   \n",
       "8  Jordan Peterson: Life, Death, Power, Fame, and...        8   \n",
       "9  Jordan Peterson: Life, Death, Power, Fame, and...        9   \n",
       "\n",
       "                                             content  token  \n",
       "0   battle not with monsters, lest ye become a mo...     52  \n",
       "1  And if you gaze into the abyss, the abyss gaze...     62  \n",
       "2                                             Right.      6  \n",
       "3                      But I would say, bring it on.     29  \n",
       "4  If you gaze into the abyss long enough, you se...     76  \n",
       "5                           Are you sure about that?     24  \n",
       "6                         I'm betting my life on it.     26  \n",
       "7  Following is a conversation with Jordan Peters...    170  \n",
       "8    This is the Lex Friedman podcast to support it.     47  \n",
       "9  Please check out our sponsors in the description.     49  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('video_text_long.csv', header=0, names=[\"title\", \"heading\", \"content\", \"token\"])\n",
    "print(f\"{len(df)} rows in the data.\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the transcript and query embeddings\n",
    "COMPLETIONS_MODEL = \"text-davinci-003\"\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
    "\n",
    "prompt = \"Why should you start being selfish?\"\n",
    "\n",
    "def get_embedding(text: str, model: str=EMBEDDING_MODEL) -> list[float]:\n",
    "    result = openai.Embedding.create(\n",
    "      model=model,\n",
    "      input=text\n",
    "    )\n",
    "    return result[\"data\"][0][\"embedding\"]\n",
    "\n",
    "def compute_doc_embeddings(df: pd.DataFrame) -> dict[tuple[str, str], list[float]]:\n",
    "    \"\"\"\n",
    "    Create an embedding for each row in the dataframe using the OpenAI Embeddings API.\n",
    "    \n",
    "    Return a dictionary that maps between each embedding vector and the index of the row that it corresponds to.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        idx: get_embedding(r.content) for idx, r in df.iterrows()\n",
    "    }\n",
    "\n",
    "def load_embeddings(fname: str) -> dict[tuple[str, str], list[float]]:\n",
    "    \"\"\"\n",
    "    Read the document embeddings and their keys from a CSV.\n",
    "    \n",
    "    fname is the path to a CSV with exactly these named columns: \n",
    "        \"title\", \"heading\", \"0\", \"1\", ... up to the length of the embedding vectors.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(fname, header=0)\n",
    "    max_dim = max([int(c) for c in df.columns if c != \"title\" and c != \"heading\"])\n",
    "    return {\n",
    "           (r.title, r.heading): [r[str(i)] for i in range(max_dim + 1)] for _, r in df.iterrows()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = \"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\"\n",
    "test_emb = get_embedding(prompt, EMBEDDING_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "*** RESULT ***\n",
    "\n",
    "{\n",
    "  \"data\": [\n",
    "    {\n",
    "      \"embedding\": [\n",
    "        -0.006929283495992422,\n",
    "        -0.005336422007530928,\n",
    "        ...\n",
    "        -4.547132266452536e-05,\n",
    "        -0.024047505110502243\n",
    "      ],\n",
    "      \"index\": 0,\n",
    "      \"object\": \"embedding\"\n",
    "    }\n",
    "  ],\n",
    "  \"model\": \"text-embedding-ada-002\",\n",
    "  \"object\": \"list\",\n",
    "  \"usage\": {\n",
    "    \"prompt_tokens\": 5,\n",
    "    \"total_tokens\": 5\n",
    "  }\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "14a9cbf84dd4a29b46cdff894ec5e0ef4cc44a632636ec2c548fb4524f05c5e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
