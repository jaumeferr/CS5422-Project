{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import sys\n",
    "\n",
    "import openai\n",
    "import whisper\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import tiktoken\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pytube import YouTube\n",
    "\n",
    "# Replace this with the location of your lib path\n",
    "sys.path.append('/home/ubuntu/CS5224-Project/lib/')\n",
    "from gpt3summarizer import GPT3Summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = whisper.load_model('base')\n",
    "nltk.download('punkt')  # download the NLTK tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Crawling and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INFO: I have also added the sample document embedding for long form video (doc_embeddings_long.pickle) - so you dont have to re-download and re-transcribe the videos from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Download and Transcribe Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Video\n",
    "\n",
    "v_url_short = \"https://www.youtube.com/watch?v=DuaTGng9tRU\"\n",
    "v_url_long = \"https://www.youtube.com/watch?v=sY8aFSY2zv4\"\n",
    "youtube_video = YouTube(v_url) # Select YT video\n",
    "\n",
    "print(youtube_video.title)\n",
    "\n",
    "audio_stream_set = youtube_video.streams.filter(only_audio = True)\n",
    "audio_stream = audio_stream_set.first() # Select quality audio stream\n",
    "\n",
    "try:\n",
    "    audio_stream.download(filename = 'test_video.mp4') # Download video\n",
    "except Exception as e:\n",
    "    print(\"An error occured: e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transcribe and save text as csv divided by sentences\n",
    "path = 'test_video.mp4'\n",
    "t_model = whisper.transcribe(model= model, audio= 'test_video.mp4', fp16 = False) # Get transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and save as csv file\n",
    "transcript = t_model['text']\n",
    "\n",
    "# create a Pandas DataFrame with one row for each sentence\n",
    "trans_df = pd.DataFrame({'content': nltk.sent_tokenize(transcript)})\n",
    "\n",
    "# add a new column with the length of each sentence\n",
    "trans_df['title'] = youtube_video.title\n",
    "trans_df['token'] = trans_df['content'].apply(len)\n",
    "trans_df = trans_df.reset_index()\n",
    "trans_df = trans_df[['title', 'index', 'content', 'token']]\n",
    "\n",
    "# save the DataFrame to a CSV file\n",
    "trans_df.to_csv('video_text_long.csv', index=False)\n",
    "\n",
    "# print the DataFrame\n",
    "trans_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Transcribed CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('video_text_long.csv', header=0, names=[\"title\", \"heading\", \"content\", \"token\"])\n",
    "print(f\"{len(df)} rows in the data.\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning GPT3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = \"\"\n",
    "\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text: str, model: str=EMBEDDING_MODEL):\n",
    "    if text is not None:\n",
    "        try:\n",
    "            result = openai.Embedding.create(\n",
    "              model=model,\n",
    "              input=text\n",
    "            )\n",
    "            return result[\"data\"][0][\"embedding\"]\n",
    "        except:\n",
    "            return \"Rate Limit Reached\"\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_doc_embeddings(df: pd.DataFrame, label:str):\n",
    "    \"\"\"\n",
    "    Create an embedding for each row in the dataframe using the OpenAI Embeddings API.\n",
    "    \n",
    "    Return a dictionary that maps between each embedding vector and the index of the row that it corresponds to.\n",
    "    \"\"\"\n",
    "    embeddings_dict = {}\n",
    "    \n",
    "    for idx, r in tqdm(df.iterrows()):\n",
    "        embedding = get_embedding(r[label])\n",
    "        \n",
    "        # Delay 60s if rate limit reached\n",
    "        if type(embedding) == str:\n",
    "            time.sleep(60)\n",
    "            embedding = get_embedding(r[label])\n",
    "        \n",
    "        embeddings_dict[idx] = embedding\n",
    "    \n",
    "    return embeddings_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_embeddings = compute_doc_embeddings(df, label=\"content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save embeddings as pickle\n",
    "with open('doc_embeddings_long.pickle', 'wb') as f:\n",
    "    pickle.dump(document_embeddings, f, protocol= pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Similar Documents Using Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_similarity(x, y):\n",
    "    \"\"\"\n",
    "    Returns the similarity between two vectors.\n",
    "    \n",
    "    Because OpenAI Embeddings are normalized to length 1, the cosine similarity is the same as the dot product.\n",
    "    \"\"\"\n",
    "    if x is not None and y is not None:\n",
    "        return np.dot(np.array(x), np.array(y))\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def order_document_sections_by_query_similarity(query, contexts):\n",
    "    \"\"\"\n",
    "    Find the query embedding for the supplied query, and compare it against all of the pre-calculated document embeddings\n",
    "    to find the most relevant sections. \n",
    "    \n",
    "    Return the list of document sections, sorted by relevance in descending order.\n",
    "    \"\"\"\n",
    "    query_embedding = get_embedding(query)\n",
    "    \n",
    "    document_similarities = sorted([\n",
    "        (vector_similarity(query_embedding, doc_embedding), doc_index) for doc_index, doc_embedding in contexts.items()\n",
    "    ], reverse=True)\n",
    "    \n",
    "    return document_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "order_document_sections_by_query_similarity(\"How did Jordan Peterson feel about Trudeau?\", document_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "def construct_prompt(question: str, context_embeddings: dict, df: pd.DataFrame, label:str, \n",
    "                     MAX_SECTION_LEN = 1000, SEPARATOR = \"\\n* \", ENCODING = \"gpt2\", debug=False):\n",
    "    most_relevant_document_sections = order_document_sections_by_query_similarity(question, context_embeddings)\n",
    "    \n",
    "    chosen_sections = []\n",
    "    chosen_sections_len = 0\n",
    "    chosen_sections_indexes = []\n",
    "    \n",
    "    encoding = tiktoken.get_encoding(ENCODING)\n",
    "    separator_len = len(encoding.encode(SEPARATOR))\n",
    "     \n",
    "    for _, section_index in most_relevant_document_sections:\n",
    "        # Add contexts until we run out of space.        \n",
    "        document_section = df.loc[section_index][label]\n",
    "        \n",
    "        if document_section is None:\n",
    "            continue\n",
    "\n",
    "        chosen_sections_len += num_tokens_from_string(document_section, ENCODING) + separator_len\n",
    "        if chosen_sections_len > MAX_SECTION_LEN:\n",
    "            break\n",
    "            \n",
    "        chosen_sections.append(SEPARATOR + document_section.replace(\"\\n\", \" \"))\n",
    "        chosen_sections_indexes.append(str(section_index))\n",
    "            \n",
    "    # Useful diagnostic information\n",
    "    if debug:\n",
    "        print(f\"Selected {len(chosen_sections)} document sections:\")\n",
    "        print(\"\\n\".join(chosen_sections_indexes))\n",
    "    \n",
    "    return chosen_sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the transcript and query embeddings\n",
    "question_prompt = \"What does the person think of religion?\"\n",
    "max_sentences = 10\n",
    "\n",
    "context = construct_prompt(question_prompt, document_embeddings, df, label=\"content\", MAX_SECTION_LEN = 1000)\n",
    "\n",
    "prompt = f\"Instructions:\\nAnswer the question as truthfully as possible using the conversation snippets of a podcast. \"\n",
    "prompt += f\"If the answer is not contained within the text below, say 'I dont know.'. \"\n",
    "prompt += f\"Limit your answer to a paragraph of {max_sentences} sentences. \"\n",
    "prompt += f\"\\n\\nContext: {''.join(context)}\"\n",
    "prompt += f\"\\n\\nQuestion: {question_prompt}\"\n",
    "prompt += f\"\\n\\nAnswer: \"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[\n",
    "                        {\"role\": \"system\", \"content\": \"You are an AI assistant that summarizes podcasts\"},\n",
    "                        {\"role\": \"user\", \"content\": prompt},\n",
    "                    ]\n",
    "            )\n",
    "choices = response.choices\n",
    "if choices:\n",
    "    content = choices[0].message.content\n",
    "    total_tokens = response.usage.total_tokens\n",
    "else:\n",
    "    print(response)\n",
    "    Exception(\"No choices returned from GPT-3 API using model 'gpt-3.5-turbo'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "14a9cbf84dd4a29b46cdff894ec5e0ef4cc44a632636ec2c548fb4524f05c5e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
